{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WkiYSRbWpTmy"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==3.0.0 --quiet\n",
        "!pip3 install fastBPE --quiet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install py-rouge --quiet\n",
        "!pip install textstat --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwIAGYWVpdva",
        "outputId": "81425a8b-1817-45c0-bd4d-e448f55a95fd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 56 kB 2.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 105 kB 8.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 61.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGaROwvmpqQL",
        "outputId": "5d7c1597-2c88-4b42-b120-f945b7729324"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKkYLCWQps-P",
        "outputId": "3cd8f2a3-2ef7-4194-b0ea-8fd6b81f2dc4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 31167, done.\u001b[K\n",
            "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 31167 (delta 0), reused 1 (delta 0), pack-reused 31166\u001b[K\n",
            "Receiving objects: 100% (31167/31167), 21.47 MiB | 7.59 MiB/s, done.\n",
            "Resolving deltas: 100% (23003/23003), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --editable ./fairseq/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd6FOgzapvbA",
        "outputId": "c997ea5c-e8bb-4e8b-adfe-8955e70448e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+f862ff5) (0.29.28)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+f862ff5) (0.10.0+cu111)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+f862ff5) (1.21.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+f862ff5) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+f862ff5) (4.64.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+f862ff5) (1.10.0+cu111)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 69.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+f862ff5) (1.15.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+f862ff5) (5.6.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 77.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+f862ff5) (4.1.1)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.7 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+f862ff5) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+f862ff5) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+f862ff5) (3.8.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=a3a90fac62bbfc953312ad7c5a404bd34a1f26a81ba71e1aa238877cb203b7d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.4.1 colorama-0.4.4 fairseq hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.4.0 sacrebleu-2.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://public.vinai.io/BERTweet_base_transformers.tar.gz\n",
        "!tar -xzvf BERTweet_base_transformers.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHo_YMOCpy4K",
        "outputId": "031070fe-38a0-4edb-cd53-1b85bf23cf09"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-04-17 08:44:04--  https://public.vinai.io/BERTweet_base_transformers.tar.gz\n",
            "Resolving public.vinai.io (public.vinai.io)... 52.84.162.15, 52.84.162.17, 52.84.162.36, ...\n",
            "Connecting to public.vinai.io (public.vinai.io)|52.84.162.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 322076118 (307M) [application/x-tar]\n",
            "Saving to: ‘BERTweet_base_transformers.tar.gz’\n",
            "\n",
            "BERTweet_base_trans 100%[===================>] 307.16M  28.4MB/s    in 15s     \n",
            "\n",
            "2022-04-17 08:44:22 (20.9 MB/s) - ‘BERTweet_base_transformers.tar.gz’ saved [322076118/322076118]\n",
            "\n",
            "BERTweet_base_transformers/\n",
            "BERTweet_base_transformers/config.json\n",
            "BERTweet_base_transformers/bpe.codes\n",
            "BERTweet_base_transformers/model.bin\n",
            "BERTweet_base_transformers/dict.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone the repo\n",
        "!git clone \"https://github.com/vudeshmukh14/MTLTS\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWHKgFGhqClL",
        "outputId": "d11a0c37-bd77-44b4-e318-4ee076021d99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MTLTS'...\n",
            "remote: Enumerating objects: 118, done.\u001b[K\n",
            "remote: Counting objects: 100% (118/118), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 118 (delta 19), reused 115 (delta 19), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (118/118), 184.88 MiB | 23.31 MiB/s, done.\n",
            "Resolving deltas: 100% (19/19), done.\n",
            "Checking out files: 100% (88/88), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd MTLTS/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuPMQR_Squx8",
        "outputId": "372956b4-20a5-41d8-97cf-f9558854c73e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTLTS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Codes/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI_elQeCqvf4",
        "outputId": "f8a4776e-0ab6-47f8-b9a1-742ceff959c6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/MTLTS/Codes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "!python mtlts.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYYE5V4Aq5QV",
        "outputId": "f7010b67-4033-428b-bd0b-feb0f78a2625"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU_ID = 0\n",
            "\n",
            "MODEL_NAME = BERT\n",
            "IN_FEATURES = 768\n",
            "OUT_FEATURES = 128\n",
            "MODEL_SAVING_POLICY = loss\n",
            "VERI_LOSS_FN = nw\n",
            "SUMM_LOSS_FN = w\n",
            "LAMBDA = 0.7\n",
            "DELTA = 0.01\n",
            "FLOOD = n\n",
            "OPTIM = adam\n",
            "L2_REGULARIZER = y\n",
            "WEIGHT_DECAY = 0.01\n",
            "USE_DROPOUT = n\n",
            "NUM_ITERATIONS = 10\n",
            "BATCH_SIZE = 16\n",
            "LEARNING_RATES = [1e-06, 2e-06, 5e-06, 1e-05]\n",
            "TRAINABLE_LAYERS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "\n",
            "TEST_FILE = german\n",
            "\n",
            "SEED = 1955\n",
            "\n",
            "\n",
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n",
            "charliehebdo.txt Training Set Size: 1872, Validation Set Size: 207, Total: 2079\n",
            "germanwings-crash.txt Training Set Size: 423, Validation Set Size: 46, Total: 469\n",
            "ottawashooting.txt Training Set Size: 801, Validation Set Size: 89, Total: 890\n",
            "sydneysiege.txt Training Set Size: 1099, Validation Set Size: 122, Total: 1221\n",
            "Test file: charliehebdo.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 1221, Total rumors: 1102\n",
            "Total non-summary-tweets: 2051, Total summary-tweets: 272\n",
            "Verification Class Weight Vector: tensor([0.9513, 1.0540], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([1.1080], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5663, 4.2702], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([7.5404], device='cuda:0')\n",
            "Test file: germanwings-crash.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 2466, Total rumors: 1306\n",
            "Total non-summary-tweets: 3334, Total summary-tweets: 438\n",
            "Verification Class Weight Vector: tensor([0.7648, 1.4441], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([1.8882], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5657, 4.3059], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([7.6119], device='cuda:0')\n",
            "Test file: ottawashooting.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 2305, Total rumors: 1089\n",
            "Total non-summary-tweets: 3000, Total summary-tweets: 394\n",
            "Verification Class Weight Vector: tensor([0.7362, 1.5583], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([2.1166], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5657, 4.3071], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([7.6142], device='cuda:0')\n",
            "Test file: sydneysiege.txt\n",
            "Statistics of training corpus:\n",
            "Total non-rumors: 2048, Total rumors: 1048\n",
            "Total non-summary-tweets: 2760, Total summary-tweets: 336\n",
            "Verification Class Weight Vector: tensor([0.7559, 1.4771], device='cuda:0', dtype=torch.float64)\n",
            "Verification Positive Class Weight Vector: tensor([1.9542], device='cuda:0')\n",
            "Summary Class Weight Vector: tensor([0.5609, 4.6071], device='cuda:0', dtype=torch.float64)\n",
            "Summary Positive Class Weight Vector: tensor([8.2143], device='cuda:0')\n",
            "\n",
            "\n",
            "\n",
            "Training with LR:  1e-06\n",
            "model intialising...\n",
            "Downloading: 100% 433/433 [00:00<00:00, 644kB/s]\n",
            "Downloading: 100% 436M/436M [00:06<00:00, 64.4MB/s]\n",
            "model intialising...\n",
            "L2_REGULARIZER = y and WEIGHT_DECAY = 0.01\n",
            "Training Set: {'ottawashooting.txt', 'sydneysiege.txt', 'charliehebdo.txt'}\n",
            "size of training data 3772\n",
            "Size of test data 469\n",
            "\n",
            "training started....\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  0\n",
            "Verifier Training Loss:  tensor(0.6833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.5694591728525981\n",
            "Validation loss:  tensor(0.6937, device='cuda:0')\n",
            "Verification Validation accuracy:  0.4880382775119617\n",
            "Verification Validation f1 score:  0.4879913913501386\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  1\n",
            "Verifier Training Loss:  tensor(0.6584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.6418345705196182\n",
            "Validation loss:  tensor(0.6480, device='cuda:0')\n",
            "Verification Validation accuracy:  0.6555023923444976\n",
            "Verification Validation f1 score:  0.3959537572254335\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  2\n",
            "Verifier Training Loss:  tensor(0.6339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.6540296924708378\n",
            "Validation loss:  tensor(0.6329, device='cuda:0')\n",
            "Verification Validation accuracy:  0.6578947368421053\n",
            "Verification Validation f1 score:  0.40342332451719154\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  3\n",
            "Verifier Training Loss:  tensor(0.6011, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.6675503711558854\n",
            "Validation loss:  tensor(0.5778, device='cuda:0')\n",
            "Verification Validation accuracy:  0.6770334928229665\n",
            "Verification Validation f1 score:  0.46539718630098054\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  4\n",
            "Verifier Training Loss:  tensor(0.5527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.7131495227995758\n",
            "Validation loss:  tensor(0.5499, device='cuda:0')\n",
            "Verification Validation accuracy:  0.7057416267942583\n",
            "Verification Validation f1 score:  0.5628172750695135\n",
            "Validation accuracy of the model is  0.7057416267942583\n",
            "Validation loss of the model is  tensor(0.5499, device='cuda:0')\n",
            "Now Testing: germanwings-crash.txt\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "Speed: 4.13 docs / s\n",
            "\n",
            "Total Test trees evaluated: 469\n",
            "Accuracy: 0.599147\n",
            "Precision: 0.837838\n",
            "Macro Precision: 0.696134\n",
            "Recall: 0.260504\n",
            "Macro Recall: 0.604278\n",
            "Micro F1 score: 0.397436\n",
            "Macro F1 score: 0.548558\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.55443   0.94805   0.69968       231\n",
            "           1    0.83784   0.26050   0.39744       238\n",
            "\n",
            "    accuracy                        0.59915       469\n",
            "   macro avg    0.69613   0.60428   0.54856       469\n",
            "weighted avg    0.69825   0.59915   0.54630       469\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "confusion matrix  [[219  12]\n",
            " [176  62]]\n",
            "For alpha=0\n",
            "\n",
            "Summary generated for: german\n",
            "Total tweets: 13\n",
            "Total verified: 13\n",
            "Total later verified: 0\n",
            "Summary length with normalized tweets: 253\n",
            "Summary length with original tweets: 249\n",
            "Summary length with clean tweets: 242\n",
            "Verified_Ratio of tweets: 1.0\n",
            "Modified verified_Ratio of tweets: 1.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Original_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 44.48\tR: 35.25\tF1: 39.33\n",
            "\trouge-2:\tP: 16.26\tR: 12.88\tF1: 14.37\n",
            "\trouge-l:\tP: 48.27\tR: 39.76\tF1: 43.60\n",
            "\trouge-w:\tP: 20.96\tR:  9.06\tF1: 12.65\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 44.48\tR: 35.25\tF1: 39.33\n",
            "\trouge-2:\tP: 16.26\tR: 12.88\tF1: 14.37\n",
            "\trouge-l:\tP: 48.27\tR: 39.76\tF1: 43.60\n",
            "\trouge-w:\tP: 20.96\tR:  9.06\tF1: 12.65\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 44.48\tR: 35.25\tF1: 39.33\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP: 16.26\tR: 12.88\tF1: 14.37\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 48.27\tR: 39.76\tF1: 43.60\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 20.96\tR:  9.06\tF1: 12.65\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Cleaned_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 38.43\tR: 33.21\tF1: 35.63\n",
            "\trouge-2:\tP:  7.47\tR:  6.45\tF1:  6.92\n",
            "\trouge-l:\tP: 42.63\tR: 37.75\tF1: 40.05\n",
            "\trouge-w:\tP: 17.26\tR:  8.56\tF1: 11.45\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 38.43\tR: 33.21\tF1: 35.63\n",
            "\trouge-2:\tP:  7.47\tR:  6.45\tF1:  6.92\n",
            "\trouge-l:\tP: 42.63\tR: 37.75\tF1: 40.05\n",
            "\trouge-w:\tP: 17.26\tR:  8.56\tF1: 11.45\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 38.43\tR: 33.21\tF1: 35.63\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP:  7.47\tR:  6.45\tF1:  6.92\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 42.63\tR: 37.75\tF1: 40.05\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 17.26\tR:  8.56\tF1: 11.45\n",
            "\n",
            "\n",
            "For alpha=0.5\n",
            "\n",
            "Summary generated for: german\n",
            "Total tweets: 13\n",
            "Total verified: 11\n",
            "Total later verified: 2\n",
            "Summary length with normalized tweets: 254\n",
            "Summary length with original tweets: 246\n",
            "Summary length with clean tweets: 243\n",
            "Verified_Ratio of tweets: 0.8461538461538461\n",
            "Modified verified_Ratio of tweets: 1.0\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Original_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 47.16\tR: 38.52\tF1: 42.41\n",
            "\trouge-2:\tP: 16.78\tR: 13.70\tF1: 15.08\n",
            "\trouge-l:\tP: 51.23\tR: 43.29\tF1: 46.92\n",
            "\trouge-w:\tP: 23.00\tR: 10.26\tF1: 14.19\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 47.16\tR: 38.52\tF1: 42.41\n",
            "\trouge-2:\tP: 16.78\tR: 13.70\tF1: 15.08\n",
            "\trouge-l:\tP: 51.23\tR: 43.29\tF1: 46.92\n",
            "\trouge-w:\tP: 23.00\tR: 10.26\tF1: 14.19\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 47.16\tR: 38.52\tF1: 42.41\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP: 16.78\tR: 13.70\tF1: 15.08\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 51.23\tR: 43.29\tF1: 46.92\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 23.00\tR: 10.26\tF1: 14.19\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Cleaned_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 40.74\tR: 35.36\tF1: 37.86\n",
            "\trouge-2:\tP:  7.85\tR:  6.81\tF1:  7.29\n",
            "\trouge-l:\tP: 45.32\tR: 40.27\tF1: 42.64\n",
            "\trouge-w:\tP: 18.78\tR:  9.35\tF1: 12.48\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 40.74\tR: 35.36\tF1: 37.86\n",
            "\trouge-2:\tP:  7.85\tR:  6.81\tF1:  7.29\n",
            "\trouge-l:\tP: 45.32\tR: 40.27\tF1: 42.64\n",
            "\trouge-w:\tP: 18.78\tR:  9.35\tF1: 12.48\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 40.74\tR: 35.36\tF1: 37.86\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP:  7.85\tR:  6.81\tF1:  7.29\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 45.32\tR: 40.27\tF1: 42.64\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 18.78\tR:  9.35\tF1: 12.48\n",
            "\n",
            "\n",
            "For alpha=1\n",
            "\n",
            "Summary generated for: german\n",
            "Total tweets: 15\n",
            "Total verified: 4\n",
            "Total later verified: 5\n",
            "Summary length with normalized tweets: 255\n",
            "Summary length with original tweets: 249\n",
            "Summary length with clean tweets: 239\n",
            "Verified_Ratio of tweets: 0.26666666666666666\n",
            "Modified verified_Ratio of tweets: 0.6\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Original_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 45.08\tR: 38.80\tF1: 41.70\n",
            "\trouge-2:\tP: 18.47\tR: 15.89\tF1: 17.08\n",
            "\trouge-l:\tP: 50.88\tR: 44.90\tF1: 47.70\n",
            "\trouge-w:\tP: 22.77\tR: 10.70\tF1: 14.56\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 45.08\tR: 38.80\tF1: 41.70\n",
            "\trouge-2:\tP: 18.47\tR: 15.89\tF1: 17.08\n",
            "\trouge-l:\tP: 50.88\tR: 44.90\tF1: 47.70\n",
            "\trouge-w:\tP: 22.77\tR: 10.70\tF1: 14.56\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 45.08\tR: 38.80\tF1: 41.70\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP: 18.47\tR: 15.89\tF1: 17.08\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 50.88\tR: 44.90\tF1: 47.70\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 22.77\tR: 10.70\tF1: 14.56\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Metric for:  Cleaned_summary\n",
            "Evaluation with Avg\n",
            "\trouge-1:\tP: 36.40\tR: 31.07\tF1: 33.53\n",
            "\trouge-2:\tP:  7.14\tR:  6.09\tF1:  6.58\n",
            "\trouge-l:\tP: 42.25\tR: 37.03\tF1: 39.47\n",
            "\trouge-w:\tP: 17.71\tR:  8.68\tF1: 11.65\n",
            "\n",
            "Evaluation with Best\n",
            "\trouge-1:\tP: 36.40\tR: 31.07\tF1: 33.53\n",
            "\trouge-2:\tP:  7.14\tR:  6.09\tF1:  6.58\n",
            "\trouge-l:\tP: 42.25\tR: 37.03\tF1: 39.47\n",
            "\trouge-w:\tP: 17.71\tR:  8.68\tF1: 11.65\n",
            "\n",
            "Evaluation with Individual\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-1:\tP: 36.40\tR: 31.07\tF1: 33.53\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-2:\tP:  7.14\tR:  6.09\tF1:  6.58\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-l:\tP: 42.25\tR: 37.03\tF1: 39.47\n",
            "\n",
            "\tHypothesis #0 & Reference #0: \n",
            "\t\trouge-w:\tP: 17.71\tR:  8.68\tF1: 11.65\n",
            "\n",
            "\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  5\n",
            "Verifier Training Loss:  tensor(0.5103, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.7494697773064687\n",
            "Validation loss:  tensor(0.5031, device='cuda:0')\n",
            "Verification Validation accuracy:  0.7535885167464115\n",
            "Verification Validation f1 score:  0.6626787323226387\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  6\n",
            "Verifier Training Loss:  tensor(0.4833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.7717391304347826\n",
            "Validation loss:  tensor(0.4731, device='cuda:0')\n",
            "Verification Validation accuracy:  0.7894736842105263\n",
            "Verification Validation f1 score:  0.7301405640167855\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  7\n",
            "Verifier Training Loss:  tensor(0.4620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.7892364793213149\n",
            "Validation loss:  tensor(0.4810, device='cuda:0')\n",
            "Verification Validation accuracy:  0.80622009569378\n",
            "Verification Validation f1 score:  0.7577331759149941\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n",
            "validation started.. 418\n",
            "\n",
            "Iteration  8\n",
            "Verifier Training Loss:  tensor(0.4478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Verification Training accuracy:  0.8001060445387063\n",
            "Validation loss:  tensor(0.4399, device='cuda:0')\n",
            "Verification Validation accuracy:  0.8229665071770335\n",
            "Verification Validation f1 score:  0.7868816315281797\n",
            "train verifier\n",
            "train summarizer\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "mtlts.py:836: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
            "  clip_grad_norm(net.parameters(), args.max_norm)\n"
          ]
        }
      ]
    }
  ]
}